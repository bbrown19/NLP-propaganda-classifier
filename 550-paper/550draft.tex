%
% File acl2015.tex
%
% Contact: car@ir.hit.edu.cn, gdzhou@suda.edu.cn
%%
%% Based on the style files for ACL-2014, which were, in turn,
%% Based on the style files for ACL-2013, which were, in turn,
%% Based on the style files for ACL-2012, which were, in turn,
%% based on the style files for ACL-2011, which were, in turn, 
%% based on the style files for ACL-2010, which were, in turn, 
%% based on the style files for ACL-IJCNLP-2009, which were, in turn,
%% based on the style files for EACL-2009 and IJCNLP-2008...

%% Based on the style files for EACL 2006 by 
%%e.agirre@ehu.es or Sergi.Balari@uab.es
%% and that of ACL 08 by Joakim Nivre and Noah Smith

\documentclass[11pt]{article}
\usepackage{acl2015}
\usepackage{times}
\usepackage{url}
\usepackage{latexsym}

%\setlength\titlebox{5cm}

% You can expand the titlebox if you need extra space
% to show all the authors. Please do not make the titlebox
% smaller than 5cm (the original size); we will check this
% in the camera-ready version and ask you to change it back.


\title{Detecting Propaganda Using N-Gram Classification Models (Working Title)}

\author{Brigit Brown \\
260779259 \\\And
 Alana Ceci \\
  260715909 \\
  \\\And
  Kaan Yilmaz \\
  260706265}

\date{}

\begin{document}
\maketitle
\begin{abstract}

In this paper, we present an approach to detect propaganda in news media. Given a sentence or headline from an article, we employ Logistic Regression, Naive Bayes and SVM to classify sentences as containing propaganda or not. We evaluate the performance of these models and compare the results to more sophisticated language models such as a long short-term memory networks model (LSTM) and BERT. The main contribution of our work is the size and diversity of our data set. We provide a comparison to previous work done to detect propaganda in news sources which were limited to narrower data that was more specific to the task. 
\end{abstract}

\section{Introduction}

Since its inception, social media has continued to change the way in which we interact with one another.  It is unique in its ability to reach millions of users instantaneously, which presents an increasingly-dangerous challenge: the inevitability of encountering fake news. The propagation of fake news gives rise to social ramifications such as influencing the outcome of elections or increasing fear and intolerance. False and biased news is often presented to promote propaganda, which is the deliberate spreading of ideas with the aim of influencing the opinions and actions of others. One of the dangers of propaganda in fake news is how difficult it is to decipher if the information that is presented is reliable and unbiased - so much so that human users cannot always know. Thus, the ability to accurately detect propagandistic articles using a natural language processing model raises an interesting concern, and it makes one question the responsibility of social media platforms to notify users of an article's attempt to influence the reader's opinions.

In this report, we present sentence-level classification algorithms to detect propaganda in data from multiple news sources. We train Logistic Regression, SVM and Naive Bayes models to provide a baseline classification of the presence or absence of propaganda in a sentence.  We compare these results to the performance of BERT and LSTM, which offer a more complex modelling of language. 


\section{Related Works}
Propaganda is defined by \cite{blah} as blah blah blah. In this section we will expand on how we differentiate propaganda and fake news compared to other work, and how we aggregated data from multiple sources, as described in Section \ref{data}.
\subsection{Detecting Fake News}



\subsection{Detecting Propaganda}

\section{Data Sources}
\label{data}


\section{Method}
We conducted experiments using Model 1, Model 2 and Model 3.

\subsection{Model 1}
\subsection{Model 2}
\subsection{Model 3}



\section{Results}



\section{Conclusion}



\section*{Statement of Contributions}

\section* {Acknowledgements}


% include your own bib file like this:
%\bibliographystyle{acl}
%\bibliography{acl2015}

\bibliographystyle{acl}
\bibliography{bib}

\end{document}